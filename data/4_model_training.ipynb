{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bundesliga Predictor: Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the data into training and test sets: Split your data into a training set and a test set. The training set will be used to train your model, while the test set will be used to evaluate its performance.\n",
    "* Choose an appropriate ordinal classification algorithm: There are several algorithms you can use to perform ordinal classification, such as the proportional odds model, the continuation ratio model, and the ordered probit model. Choose the algorithm that best fits your data and problem.\n",
    "* Train the model: Fit the selected model to the training set, using the home and away scores as the target variables and the remaining features as predictors.\n",
    "* Evaluate the model: Use the test set to evaluate the performance of your model. You can use metrics such as accuracy, mean absolute error, or mean squared error to assess how well the model predicts the scores.\n",
    "* Tune the model: If necessary, you can tune the model by adjusting its hyperparameters to improve its performance. You can use techniques such as grid search or randomized search to find the best combination of hyperparameters.\n",
    "* Deploy the model: Once you are satisfied with the performance of your model, you can deploy it to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HomeGoals  AwayGoals  HLH_03  HWH_03    HWH_15  AWA_03  ALA_03    ALA_15  \\\n",
      "0          3          1       1       2  0.923077       1       1  0.923077   \n",
      "1          1          2       1       1  0.692308       0       1  0.692308   \n",
      "2          0          2       1       2  0.538462       0       3  0.538462   \n",
      "3          1          0       1       1  0.307692       2       0  0.307692   \n",
      "4          2          0       0       3  0.615385       1       1  0.615385   \n",
      "\n",
      "     HGA_15    AGA_15  ...    HGA_03    AGF_03    AGF_15    AGA_03    HST_15  \\\n",
      "0  0.923077  0.923077  ...  2.449490  2.449490  4.795832  2.236068  0.923077   \n",
      "1  0.692308  0.692308  ...  1.732051  1.414214  4.123106  2.000000  0.692308   \n",
      "2  0.538462  0.538462  ...  2.000000  1.414214  4.242641  3.000000  0.538462   \n",
      "3  0.307692  0.307692  ...  3.000000  2.449490  5.196152  1.414214  0.307692   \n",
      "4  0.615385  0.615385  ...  1.414214  2.000000  5.196152  2.236068  0.615385   \n",
      "\n",
      "     AST_15    HCR_03    HCR_15    ACR_03    ACR_15  \n",
      "0  0.923077  4.472136  4.118252  3.734970  3.357082  \n",
      "1  0.692308  3.333167  3.509986  2.773085  3.116087  \n",
      "2  0.538462  3.675595  2.872281  2.828427  3.611094  \n",
      "3  0.307692  4.548626  3.713489  3.973663  3.819686  \n",
      "4  0.615385  4.263801  3.471311  3.535534  3.674235  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('bundesliga_data_preprocessed.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you wrote code for me earlier for splitting thmy preprocessed data into 3 sets: train, test and validate, with a proportion of 70%, 20% and 10%. I also wanted to use k-fold validation, as well as test a baseline model that predicts football scores randomly between 0 and 3.\n",
    "\n",
    "Here is the code you started. Please finish it:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Load the preprocessed data into a pandas dataframe\n",
    "df = pd.read_csv('preprocessed_data.csv')\n",
    "\n",
    "# Split the data into train, test, and validation sets\n",
    "train_val_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.125, random_state=42)\n",
    "\n",
    "# Set up the k-fold cross-validation\n",
    "n_splits = 5  # The number of folds\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the baseline model\n",
    "baseline_model = DummyClassifier(strategy='uniform')\n",
    "\n",
    "# Train and evaluate the baseline model using k-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_val_data)):\n",
    "    print(f'Fold {fold+1}')\n",
    "    X_train, y_train = train_val_data.iloc[train_index, :-2], train_val_data.iloc[train_index, -2:]\n",
    "    X_val, y_val = train_val_data.iloc[val_index, :-2], train_val_data.iloc[val_index, -2:]\n",
    "\n",
    "# Fit the baseline model on the training data\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the baseline model on the validation data\n",
    "baseline_score = baseline_model.score(X_val, y_val)\n",
    "\n",
    "print(f'Baseline score: {baseline_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m baseline_model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Evaluate the baseline model on the validation\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m baseline_score \u001b[39m=\u001b[39m baseline_model\u001b[39m.\u001b[39;49mscore(X_val, y_val)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBaseline score: \u001b[39m\u001b[39m{\u001b[39;00mbaseline_score\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Test the baseline model on the test set\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/dummy.py:442\u001b[0m, in \u001b[0;36mDummyClassifier.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(y), \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 442\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mscore(X, y, sample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:668\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:106\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    109\u001b[0m     y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "# Split the data into train, test, and validation sets\n",
    "train_val_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.125, random_state=42)\n",
    "\n",
    "# Set up the k-fold cross-validation\n",
    "n_splits = 5  # The number of folds\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the baseline model\n",
    "baseline_model = DummyClassifier(strategy='uniform')\n",
    "\n",
    "# Train and evaluate the baseline model using k-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_val_data)):\n",
    "    print(f'Fold {fold+1}')\n",
    "    X_train, y_train = train_val_data.iloc[train_index, :-2], train_val_data.iloc[train_index, -2:]\n",
    "    X_val, y_val = train_val_data.iloc[val_index, :-2], train_val_data.iloc[val_index, -2:]\n",
    "    \n",
    "    # Fit the baseline model on the training data\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the baseline model on the validation\n",
    "    baseline_score = baseline_model.score(X_val, y_val)\n",
    "\n",
    "    print(f'Baseline score: {baseline_score}')\n",
    "\n",
    "    # Test the baseline model on the test set\n",
    "    X_test, y_test = test_data.iloc[:, :-2], test_data.iloc[:, -2:]\n",
    "    baseline_test_score = baseline_model.score(X_test, y_test)\n",
    "    \n",
    "    print(f'Baseline test score: {baseline_test_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
